\contentsline {chapter}{\numberline {1}Introduction to Reinforcement Learning}{2}{chapter.1}%
\contentsline {section}{\numberline {1.1}What is Reinforcement Learning?}{2}{section.1.1}%
\contentsline {section}{\numberline {1.2}Some Terminology}{2}{section.1.2}%
\contentsline {section}{\numberline {1.3}Exploration vs Exploitation}{3}{section.1.3}%
\contentsline {section}{\numberline {1.4}Classical Methods}{3}{section.1.4}%
\contentsline {subsection}{\numberline {1.4.1}Game Trees}{4}{subsection.1.4.1}%
\contentsline {subsection}{\numberline {1.4.2}The Minimax Algorithm}{6}{subsection.1.4.2}%
\contentsline {section}{\numberline {1.5}The Reinforcement Learning Method}{7}{section.1.5}%
\contentsline {chapter}{\numberline {2}Multiarmed Bandits}{8}{chapter.2}%
\contentsline {section}{\numberline {2.1}Definitions}{8}{section.2.1}%
\contentsline {section}{\numberline {2.2}Balancing Exploration and Exploitation}{9}{section.2.2}%
\contentsline {subsection}{\numberline {2.2.1}The Greedy Policy}{10}{subsection.2.2.1}%
\contentsline {subsection}{\numberline {2.2.2}The $\epsilon $-Greedy Policy}{11}{subsection.2.2.2}%
\contentsline {subsection}{\numberline {2.2.3}Upper Confidence Bound Action Selection}{11}{subsection.2.2.3}%
\contentsline {subsection}{\numberline {2.2.4}Gradient Bandits}{12}{subsection.2.2.4}%
\contentsline {subsection}{\numberline {2.2.5}Thompson Sampling}{14}{subsection.2.2.5}%
\contentsline {section}{\numberline {2.3}Comparing Policies}{14}{section.2.3}%
\contentsline {section}{\numberline {2.4}Contextual Bandits}{14}{section.2.4}%
