\contentsline {chapter}{\numberline {1}Introduction to Reinforcement Learning}{3}{chapter.1}%
\contentsline {section}{\numberline {1.1}What is Reinforcement Learning?}{3}{section.1.1}%
\contentsline {section}{\numberline {1.2}Some Terminology}{3}{section.1.2}%
\contentsline {section}{\numberline {1.3}The Reward Hypothesis}{4}{section.1.3}%
\contentsline {section}{\numberline {1.4}Exploration vs Exploitation}{4}{section.1.4}%
\contentsline {section}{\numberline {1.5}Classical Methods}{4}{section.1.5}%
\contentsline {subsection}{\numberline {1.5.1}Game Trees}{5}{subsection.1.5.1}%
\contentsline {subsection}{\numberline {1.5.2}The Minimax Algorithm}{7}{subsection.1.5.2}%
\contentsline {section}{\numberline {1.6}The Reinforcement Learning Method}{8}{section.1.6}%
\contentsline {chapter}{\numberline {2}Multiarmed Bandits}{10}{chapter.2}%
\contentsline {section}{\numberline {2.1}Definitions}{10}{section.2.1}%
\contentsline {section}{\numberline {2.2}Balancing Exploration and Exploitation}{11}{section.2.2}%
\contentsline {subsection}{\numberline {2.2.1}The Greedy Policy}{12}{subsection.2.2.1}%
\contentsline {subsection}{\numberline {2.2.2}The $\varepsilon $-greedy Policy}{13}{subsection.2.2.2}%
\contentsline {subsection}{\numberline {2.2.3}Upper Confidence Bound Action Selection}{13}{subsection.2.2.3}%
\contentsline {subsection}{\numberline {2.2.4}Gradient Bandits}{14}{subsection.2.2.4}%
\contentsline {subsection}{\numberline {2.2.5}Thompson Sampling}{16}{subsection.2.2.5}%
\contentsline {section}{\numberline {2.3}Comparing Policies}{16}{section.2.3}%
\contentsline {section}{\numberline {2.4}Contextual Bandits}{16}{section.2.4}%
\contentsline {chapter}{\numberline {3}Markov Decision Processes}{18}{chapter.3}%
\contentsline {section}{\numberline {3.1}Formalization of the Reinforcement Learning Problem}{18}{section.3.1}%
\contentsline {section}{\numberline {3.2}Return and Discounting}{18}{section.3.2}%
\contentsline {section}{\numberline {3.3}Markov Decision Processes and the Markov Property}{19}{section.3.3}%
\contentsline {section}{\numberline {3.4}The Bellman Equations}{21}{section.3.4}%
\contentsline {section}{\numberline {3.5}Bellman Optimality Equations}{22}{section.3.5}%
\contentsline {section}{\numberline {3.6}Linear Programming}{23}{section.3.6}%
\contentsline {section}{\numberline {3.7}Difficulties in Linear Programming}{23}{section.3.7}%
\contentsline {chapter}{\numberline {4}Dynamic Programming}{25}{chapter.4}%
\contentsline {section}{\numberline {4.1}Introduction}{25}{section.4.1}%
\contentsline {section}{\numberline {4.2}Policy Evaluation}{25}{section.4.2}%
\contentsline {section}{\numberline {4.3}Policy Improvement}{27}{section.4.3}%
\contentsline {subsection}{\numberline {4.3.1}The Policy Improvement Theorem}{27}{subsection.4.3.1}%
\contentsline {subsection}{\numberline {4.3.2}Improving our Policy}{28}{subsection.4.3.2}%
\contentsline {section}{\numberline {4.4}Policy Iteration}{28}{section.4.4}%
\contentsline {section}{\numberline {4.5}Value Iteration}{29}{section.4.5}%
\contentsline {section}{\numberline {4.6}Asynchronous Dynamic Programming}{29}{section.4.6}%
\contentsline {section}{\numberline {4.7}Prioritized Sweeping}{30}{section.4.7}%
\contentsline {section}{\numberline {4.8}Generalized Policy Iteration}{30}{section.4.8}%
\contentsline {chapter}{\numberline {5}Monte Carlo Methods}{31}{chapter.5}%
\contentsline {section}{\numberline {5.1}Estimating the State Value Function}{31}{section.5.1}%
\contentsline {section}{\numberline {5.2}Estimating the Action Value Function}{32}{section.5.2}%
\contentsline {section}{\numberline {5.3}Problems with Visit Based Estimation}{32}{section.5.3}%
\contentsline {subsection}{\numberline {5.3.1}Exploring Starts}{32}{subsection.5.3.1}%
\contentsline {section}{\numberline {5.4}Monte Carlo ES}{32}{section.5.4}%
\contentsline {section}{\numberline {5.5}Removing the Exploring Starts Assumption}{33}{section.5.5}%
\contentsline {subsection}{\numberline {5.5.1}On-Policy Methods: $\varepsilon $-soft policies}{33}{subsection.5.5.1}%
\contentsline {subsection}{\numberline {5.5.2}Off Policy Estimation: Importance Sampling}{35}{subsection.5.5.2}%
